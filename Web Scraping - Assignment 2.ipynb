{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2adfa807",
   "metadata": {},
   "source": [
    "1. Web-SCraping for Data Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3d4564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\kumar\\appdata\\roaming\\python\\python39\\site-packages (4.7.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\kumar\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\kumar\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\kumar\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\kumar\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\kumar\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\kumar\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\kumar\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc26647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54fa8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to webdriver...\n",
    "\n",
    "driver = webdriver.Chrome(r\"C\\\\Users\\kumar\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eff761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the naukri page on automated chrome browser...\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a02e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering Designation and Location as required...\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME, \"suggestor-input \")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37972d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac20f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ae9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c93801ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page ...\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    \n",
    "# scraping job location from the given page...\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "    \n",
    "# scraping company name from the given page...\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "    \n",
    "# scraping job experience from the given page....\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1ef16af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d38d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Project Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>WSP</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst, Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(HSR Layout +1)</td>\n",
       "      <td>Clinilaunch Research Institute Llp</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru</td>\n",
       "      <td>Treebo Hotels</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Executive - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cargill</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Eli Lilly And Company</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Job_title                        Job_location  \\\n",
       "0                    Data Analyst                 Bangalore/Bengaluru   \n",
       "1                    Data Analyst                 Bangalore/Bengaluru   \n",
       "2                    Data Analyst                 Bangalore/Bengaluru   \n",
       "3          Senior Data Analyst II                 Bangalore/Bengaluru   \n",
       "4            Project Data Analyst                 Bangalore/Bengaluru   \n",
       "5  Data Analyst, Business Analyst  Bangalore/Bengaluru(HSR Layout +1)   \n",
       "6                    Data Analyst     Temp. WFH - Bangalore/Bengaluru   \n",
       "7        Executive - Data Analyst                 Bangalore/Bengaluru   \n",
       "8                    Data Analyst                 Bangalore/Bengaluru   \n",
       "9                    Data Analyst                 Bangalore/Bengaluru   \n",
       "\n",
       "                         Company_name Exp_Required  \n",
       "0                       Shell Pvt Ltd      2-5 Yrs  \n",
       "1                       Shell Pvt Ltd      3-5 Yrs  \n",
       "2                       Shell Pvt Ltd      2-5 Yrs  \n",
       "3                            Flipkart      2-4 Yrs  \n",
       "4                                 WSP      0-4 Yrs  \n",
       "5  Clinilaunch Research Institute Llp      0-5 Yrs  \n",
       "6                       Treebo Hotels      1-5 Yrs  \n",
       "7                            Flipkart      1-5 Yrs  \n",
       "8                             Cargill      2-4 Yrs  \n",
       "9               Eli Lilly And Company      2-6 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making Data Frame...\n",
    "\n",
    "df = pd.DataFrame({'Job_title': job_title,'Job_location': job_location, 'Company_name': company_name,'Exp_Required': experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad36454",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1affb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a51142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe23f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a571b96",
   "metadata": {},
   "source": [
    "2. Web-Scraping of Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b1d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and locations are required...\n",
    "designation = driver.find_element(By.CLASS_NAME, \"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28a0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH, \"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fd3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "552b1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a97c0a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the page...\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    \n",
    "    \n",
    "# scraping job location from the given page....\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "    \n",
    "    \n",
    "# scraping company name from the given page....\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "    \n",
    "# scraping Experience required from the given page....\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "046944a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c26ec3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Tata Nexarc</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Nagpur, Pune</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weather and Climate Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...</td>\n",
       "      <td>Mindtree</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "      <td>Bizongo</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Manager-Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACN - Applied Intelligence - Data Scientist - 09</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Python Programming Language Data Science Pract...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                   Analystics & Modeling Specialist   \n",
       "1                                     Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3                 Weather and Climate Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                                Data Scientist - II   \n",
       "6                              Senior Data Scientist   \n",
       "7                               Manager-Data Science   \n",
       "8   ACN - Applied Intelligence - Data Scientist - 09   \n",
       "9  Python Programming Language Data Science Pract...   \n",
       "\n",
       "                                        Job_location      Company_name  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...         Accenture   \n",
       "1  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...       Tata Nexarc   \n",
       "2                  Bangalore/Bengaluru, Nagpur, Pune     Tech Mahindra   \n",
       "3                                Bangalore/Bengaluru     Shell Pvt Ltd   \n",
       "4  Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...          Mindtree   \n",
       "5     Bangalore/Bengaluru, India, Mumbai (All Areas)           Bizongo   \n",
       "6                        Bangalore/Bengaluru, Mumbai      Baker Hughes   \n",
       "7                                Bangalore/Bengaluru  AMERICAN EXPRESS   \n",
       "8                                Bangalore/Bengaluru         Accenture   \n",
       "9                                Bangalore/Bengaluru         Accenture   \n",
       "\n",
       "  Exp_Required  \n",
       "0      6-8 Yrs  \n",
       "1      4-8 Yrs  \n",
       "2      5-8 Yrs  \n",
       "3     5-12 Yrs  \n",
       "4     5-10 Yrs  \n",
       "5      3-6 Yrs  \n",
       "6      6-8 Yrs  \n",
       "7      3-4 Yrs  \n",
       "8      2-6 Yrs  \n",
       "9      4-6 Yrs  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making DataFrame...\n",
    "\n",
    "df = pd.DataFrame({'Job_title': job_title,'Job_location': job_location, 'Company_name': company_name,'Exp_Required': experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16acd98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a35277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa1601e4",
   "metadata": {},
   "source": [
    "3. Web Scraping using the filter availble on this page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d3d6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Entering designation and location are required. \n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec651b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5991d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbf20603",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a23b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap job_title from the given page..\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "    \n",
    "    \n",
    "# scrap job_location from the given page...\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "    \n",
    "# scrap company_name from the given page...\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "# scrap experience_required from the given page...\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da4057bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artificial Intelligence/Computer Vision Engine...</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Vicara</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Activation Specialist - Adobe Target</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Temp. WFH - Noida</td>\n",
       "      <td>NGI Ventures</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Opening For Jr. Data Scientist with Tatras Dat...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Tatras Data Services</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...</td>\n",
       "      <td>torcai digital media</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Americana Restaurants (india)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>URGENT: Data Scientist | Gurugram | 5 Days Wor...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Digilytics</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Alliance Recruitment Agency</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SE/SSE-Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Bold Technology Systems</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Artificial Intelligence/Computer Vision Engine...   \n",
       "1          Data Activation Specialist - Adobe Target   \n",
       "2                  Data Scientist - Engine Algorithm   \n",
       "3                                     Data Scientist   \n",
       "4  Opening For Jr. Data Scientist with Tatras Dat...   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7  URGENT: Data Scientist | Gurugram | 5 Days Wor...   \n",
       "8                                     Data Scientist   \n",
       "9                              SE/SSE-Data Scientist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "1  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "2  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "3                                  Temp. WFH - Noida   \n",
       "4                                        Delhi / NCR   \n",
       "5  Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                   Gurgaon/Gurugram   \n",
       "8                                              Noida   \n",
       "9                                        Delhi / NCR   \n",
       "\n",
       "                    Company_name Exp_required  \n",
       "0                         Vicara      1-3 Yrs  \n",
       "1                 Okda Solutions     7-10 Yrs  \n",
       "2                   Primo Hiring      1-3 Yrs  \n",
       "3                   NGI Ventures      1-5 Yrs  \n",
       "4           Tatras Data Services      2-4 Yrs  \n",
       "5           torcai digital media      2-7 Yrs  \n",
       "6  Americana Restaurants (india)      3-8 Yrs  \n",
       "7                     Digilytics      2-5 Yrs  \n",
       "8    Alliance Recruitment Agency      3-4 Yrs  \n",
       "9        Bold Technology Systems      3-8 Yrs  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making Data Frame---\n",
    "\n",
    "df = pd.DataFrame({'Job_title': job_title,'Job_location': job_location, 'Company_name': company_name,'Exp_Required': experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930462a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101f17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "923fd439",
   "metadata": {},
   "source": [
    "4. Scraping first 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5b294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the flipkart page on automated chrome browser...\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2e0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enterning serch for product and brand more...\n",
    "\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eddf6522",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5afc64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_title = []\n",
    "product_discription = []\n",
    "product_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "226a7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap brand from the given page...\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "for i in title_tags[0:100]:\n",
    "    title = i.text\n",
    "    brand_title.append(title)\n",
    "    \n",
    "    \n",
    "# scrap product_discription from the given page...\n",
    "\n",
    "discription_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]')\n",
    "for i in discription_tags[0:100]:\n",
    "    discription = i.text\n",
    "    product_discription.append(discription)\n",
    "    \n",
    "    \n",
    "# scrap sunglaces price from the given page...\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"] ')\n",
    "for i in price_tags[0:100]:\n",
    "    price = i.text\n",
    "    product_price.append(price)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00ba18df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>Product_discription</th>\n",
       "      <th>Product_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>59% off</td>\n",
       "      <td>₹806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>57% off</td>\n",
       "      <td>₹849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>75% off</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>87% off</td>\n",
       "      <td>₹129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>87% off</td>\n",
       "      <td>₹129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>30% off</td>\n",
       "      <td>₹699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>30% off</td>\n",
       "      <td>₹629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>80% off</td>\n",
       "      <td>₹398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>37% off</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>90% off</td>\n",
       "      <td>₹159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>75% off</td>\n",
       "      <td>₹497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>80% off</td>\n",
       "      <td>₹398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>30% off</td>\n",
       "      <td>₹909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>35% off</td>\n",
       "      <td>₹579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>30% off</td>\n",
       "      <td>₹559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>87% off</td>\n",
       "      <td>₹129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>75% off</td>\n",
       "      <td>₹497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>52% off</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>20% off</td>\n",
       "      <td>₹719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>87% off</td>\n",
       "      <td>₹129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>75% off</td>\n",
       "      <td>₹616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>84% off</td>\n",
       "      <td>₹117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>88% off</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>35% off</td>\n",
       "      <td>₹649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>66% off</td>\n",
       "      <td>₹664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>85% off</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>85% off</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>71% off</td>\n",
       "      <td>₹701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>90% off</td>\n",
       "      <td>₹259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>35% off</td>\n",
       "      <td>₹519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>52% off</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>66% off</td>\n",
       "      <td>₹664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>88% off</td>\n",
       "      <td>₹188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>88% off</td>\n",
       "      <td>₹286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Sewell</td>\n",
       "      <td>81% off</td>\n",
       "      <td>₹280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>82% off</td>\n",
       "      <td>₹179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>66% off</td>\n",
       "      <td>₹664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>74% off</td>\n",
       "      <td>₹649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>74% off</td>\n",
       "      <td>₹129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>85% off</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand_name Product_discription Product_price\n",
       "0       VINCENT CHASE             59% off          ₹806\n",
       "1       VINCENT CHASE             57% off          ₹849\n",
       "2           Elligator             75% off          ₹149\n",
       "3          PHENOMENAL             87% off          ₹129\n",
       "4          LIZA ANGEL             87% off          ₹129\n",
       "5            Fastrack             30% off          ₹699\n",
       "6            Fastrack             30% off          ₹629\n",
       "7      ROZZETTA CRAFT             80% off          ₹398\n",
       "8            Fastrack             37% off          ₹499\n",
       "9   SHAAH COLLECTIONS             90% off          ₹159\n",
       "10     ROZZETTA CRAFT             75% off          ₹497\n",
       "11     ROZZETTA CRAFT             80% off          ₹398\n",
       "12           Fastrack             30% off          ₹909\n",
       "13           Fastrack             35% off          ₹579\n",
       "14           Fastrack             30% off          ₹559\n",
       "15         LIZA ANGEL             87% off          ₹129\n",
       "16     ROZZETTA CRAFT             75% off          ₹497\n",
       "17      VINCENT CHASE             52% off          ₹949\n",
       "18           Fastrack             20% off          ₹719\n",
       "19          Elligator             87% off          ₹129\n",
       "20     ROZZETTA CRAFT             75% off          ₹616\n",
       "21              NuVew             84% off          ₹117\n",
       "22               SRPM             88% off          ₹149\n",
       "23           Fastrack             35% off          ₹649\n",
       "24      VINCENT CHASE             66% off          ₹664\n",
       "25          Elligator             85% off          ₹149\n",
       "26             GANSTA             85% off          ₹299\n",
       "27      VINCENT CHASE             71% off          ₹701\n",
       "28          New Specs             90% off          ₹259\n",
       "29           Fastrack             35% off          ₹519\n",
       "30      VINCENT CHASE             52% off          ₹949\n",
       "31          ROYAL SON             66% off          ₹664\n",
       "32             PIRASO             88% off          ₹188\n",
       "33          Elligator             88% off          ₹286\n",
       "34             Sewell             81% off          ₹280\n",
       "35               SRPM             82% off          ₹179\n",
       "36      VINCENT CHASE             66% off          ₹664\n",
       "37     ROZZETTA CRAFT             74% off          ₹649\n",
       "38         LIZA ANGEL             74% off          ₹129\n",
       "39             SUNBEE             85% off          ₹149"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand_name': brand_title,'Product_discription': product_discription, 'Product_price': product_price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff075f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeb9ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56eb6181",
   "metadata": {},
   "source": [
    "5. web-Scraping review data from flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335dbc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the flipkart page on automated chrome browser...\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea949ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering serch for product name and brnad name...\n",
    "\n",
    "product = driver.find_element(By.CLASS_NAME,'_3704LK')\n",
    "product.send_keys('iphone11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23e0da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be900cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_rating = []\n",
    "review_summary = []\n",
    "full_review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60d90635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap rating from the given page...\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[2]/span[1]')\n",
    "for i in rating_tags[0:100]:\n",
    "    rating = i.text\n",
    "    product_rating.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00e463bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tags = driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[3]/ul')\n",
    "for i in summary_tags[0:100]:\n",
    "    summary = i.text\n",
    "    review_summary.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdeeeeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tags = driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[2]')\n",
    "for i in review_tags[0:100]:\n",
    "    review = i.text\n",
    "    full_review.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09d2e925",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6496\\3089114409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Making DataFrame...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Product_rating'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mproduct_rating\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Review_summary'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mreview_summary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Full_review'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfull_review\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#Making DataFrame...\n",
    "\n",
    "df = pd.DataFrame({'Product_rating': product_rating, 'Review_summary': review_summary, 'Full_review': full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c32b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a75e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43668bb0",
   "metadata": {},
   "source": [
    "6. Web-Scraping  sneekers from flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6eb4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the flipkart page on automated chrome browser...\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccceeed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = driver.find_element(By.CLASS_NAME,'_3704LK')\n",
    "product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3151539",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "552817ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_title = []\n",
    "product_discription = []\n",
    "product_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16c7ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap brand name for the given page..\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in title_tags[0:100]:\n",
    "    title = i.text\n",
    "    brand_title.append(title)\n",
    "    \n",
    "# scrap discription for the given page....\n",
    "\n",
    "discription_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2B099V\"]')\n",
    "for i in discription_tags[0:100]:\n",
    "    discription = i.text\n",
    "    product_discription.append(discription)\n",
    "    \n",
    "    \n",
    "# scrap price for the given page....\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:100]:\n",
    "    price = i.text\n",
    "    product_price.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1977fbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>Product_discription</th>\n",
       "      <th>Product_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Deals4you\\nSneakers For Women\\n₹299₹1,49980% o...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOOBON</td>\n",
       "      <td>FOOBON\\nSneakers For Men\\n₹299₹99970% off\\nSiz...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Labbin\\nSneakers For Men\\n₹399₹99960% off\\nHot...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bond Street By Red Tape</td>\n",
       "      <td>Bond Street By Red Tape\\nSneakers For Men\\n₹1,...</td>\n",
       "      <td>₹1,274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Shozie\\nSneakers For Men\\n₹295₹99970% off\\nSiz...</td>\n",
       "      <td>₹295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bond Street By Red Tape</td>\n",
       "      <td>Bond Street By Red Tape\\nSneakers For Men\\n₹1,...</td>\n",
       "      <td>₹1,274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Shozie\\nSneakers For Men\\n₹399₹99960% off\\nLow...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kardam&amp;sons</td>\n",
       "      <td>kardam&amp;sons\\nFashionable Luxury Canvas Casual ...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bond Street By Red Tape</td>\n",
       "      <td>Bond Street By Red Tape\\nSneakers For Men\\n₹1,...</td>\n",
       "      <td>₹1,274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aadi</td>\n",
       "      <td>aadi\\nMesh | Ultralightweight | Comfortable | ...</td>\n",
       "      <td>₹359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kardam&amp;sons</td>\n",
       "      <td>kardam&amp;sons\\nCanvas Casual Partywear Outdoor S...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>edisson</td>\n",
       "      <td>edisson\\nCasual Sneakers Black Outdoor Shoes F...</td>\n",
       "      <td>₹559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SFR</td>\n",
       "      <td>SFR\\nFAST Trenddy Tainer Lace-ups Sporty Casua...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>BRUTON\\nExclusive Sneaker Shoes Sneakers For M...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>BRUTON\\nLightweight Pack Of 1 Trendy Sneakers ...</td>\n",
       "      <td>₹249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>World Wear Footwear\\nLatest Exclusive Affordab...</td>\n",
       "      <td>₹259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>edisson</td>\n",
       "      <td>edisson\\n001-Original Luxury Branded Fashionab...</td>\n",
       "      <td>₹559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kardam&amp;sons</td>\n",
       "      <td>kardam&amp;sons\\nCanvas Casual Partywear Outdoor S...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SFR</td>\n",
       "      <td>SFR\\nPLANCK Smart Grey Lace-Ups Casuals Sneake...</td>\n",
       "      <td>₹209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Deals4you\\nSneakers For Women\\n₹449₹99955% off...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Roadster\\nMen Blue Solid Sneakers Sneakers For...</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BOLLERO</td>\n",
       "      <td>BOLLERO\\nTrendy Sporty Shoes For Mens Sneakers...</td>\n",
       "      <td>₹699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>BRUTON\\nLattest Sneakers Shoe Sneakers For Men...</td>\n",
       "      <td>₹279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>ASTEROID\\nColorblock men's fancy sneakers Kore...</td>\n",
       "      <td>₹494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SFR</td>\n",
       "      <td>SFR\\nPLANCK Smart Red Lace-Ups Casuals Sneaker...</td>\n",
       "      <td>₹209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aadi</td>\n",
       "      <td>aadi\\nSynthetic| Lightweight| Premiun| Comfort...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Numenzo\\nSneakers For Men\\n₹449₹1,04557% off\\n...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>JAMARION</td>\n",
       "      <td>JAMARION\\nModern Trendy Sneakers Shoes Sneaker...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bond Street By Red Tape</td>\n",
       "      <td>Bond Street By Red Tape\\nSneakers For Men\\n₹1,...</td>\n",
       "      <td>₹1,274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SFR</td>\n",
       "      <td>SFR\\nSneakers For Men\\n₹269₹99973% off\\nFree d...</td>\n",
       "      <td>₹269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>edisson</td>\n",
       "      <td>edisson\\nCasual Sneakers Canvas Shoes For Men ...</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kardam&amp;sons</td>\n",
       "      <td>kardam&amp;sons\\nCanvas Casual Partywear Outdoor S...</td>\n",
       "      <td>₹413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>World Wear Footwear\\nExclusive Affordable Coll...</td>\n",
       "      <td>₹259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Labbin\\nSneakers For Men\\n₹399₹99960% off\\nFre...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SFR</td>\n",
       "      <td>SFR\\nPLANCK Smart Blue Lace-Ups Casuals Sneake...</td>\n",
       "      <td>₹209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Robbie jones\\nSneakers For Men\\n₹439₹1,02257% ...</td>\n",
       "      <td>₹439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>kardam&amp;sons</td>\n",
       "      <td>kardam&amp;sons\\nCanvas Casual Partywear Outdoor S...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>kardam&amp;sons</td>\n",
       "      <td>kardam&amp;sons\\nCanvas Casual Partywear Outdoor S...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Kraasa\\nCasuals, Canvas, Partywear Sneakers Fo...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>RED TAPE\\nSneakers For Men\\n₹1,749₹4,99965% of...</td>\n",
       "      <td>₹1,749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Brand_name  \\\n",
       "0                 Deals4you   \n",
       "1                    FOOBON   \n",
       "2                    Labbin   \n",
       "3   Bond Street By Red Tape   \n",
       "4                    Shozie   \n",
       "5   Bond Street By Red Tape   \n",
       "6                    Shozie   \n",
       "7               kardam&sons   \n",
       "8   Bond Street By Red Tape   \n",
       "9                      aadi   \n",
       "10              kardam&sons   \n",
       "11                  edisson   \n",
       "12                      SFR   \n",
       "13                   BRUTON   \n",
       "14                   BRUTON   \n",
       "15      World Wear Footwear   \n",
       "16                  edisson   \n",
       "17              kardam&sons   \n",
       "18                      SFR   \n",
       "19                Deals4you   \n",
       "20                 Roadster   \n",
       "21                  BOLLERO   \n",
       "22                   BRUTON   \n",
       "23                 ASTEROID   \n",
       "24                      SFR   \n",
       "25                     aadi   \n",
       "26                  Numenzo   \n",
       "27                 JAMARION   \n",
       "28  Bond Street By Red Tape   \n",
       "29                      SFR   \n",
       "30                  edisson   \n",
       "31              kardam&sons   \n",
       "32      World Wear Footwear   \n",
       "33                   Labbin   \n",
       "34                      SFR   \n",
       "35             Robbie jones   \n",
       "36              kardam&sons   \n",
       "37              kardam&sons   \n",
       "38                   Kraasa   \n",
       "39                 RED TAPE   \n",
       "\n",
       "                                  Product_discription Product_price  \n",
       "0   Deals4you\\nSneakers For Women\\n₹299₹1,49980% o...          ₹299  \n",
       "1   FOOBON\\nSneakers For Men\\n₹299₹99970% off\\nSiz...          ₹299  \n",
       "2   Labbin\\nSneakers For Men\\n₹399₹99960% off\\nHot...          ₹399  \n",
       "3   Bond Street By Red Tape\\nSneakers For Men\\n₹1,...        ₹1,274  \n",
       "4   Shozie\\nSneakers For Men\\n₹295₹99970% off\\nSiz...          ₹295  \n",
       "5   Bond Street By Red Tape\\nSneakers For Men\\n₹1,...        ₹1,274  \n",
       "6   Shozie\\nSneakers For Men\\n₹399₹99960% off\\nLow...          ₹399  \n",
       "7   kardam&sons\\nFashionable Luxury Canvas Casual ...          ₹449  \n",
       "8   Bond Street By Red Tape\\nSneakers For Men\\n₹1,...        ₹1,274  \n",
       "9   aadi\\nMesh | Ultralightweight | Comfortable | ...          ₹359  \n",
       "10  kardam&sons\\nCanvas Casual Partywear Outdoor S...          ₹499  \n",
       "11  edisson\\nCasual Sneakers Black Outdoor Shoes F...          ₹559  \n",
       "12  SFR\\nFAST Trenddy Tainer Lace-ups Sporty Casua...          ₹299  \n",
       "13  BRUTON\\nExclusive Sneaker Shoes Sneakers For M...          ₹299  \n",
       "14  BRUTON\\nLightweight Pack Of 1 Trendy Sneakers ...          ₹249  \n",
       "15  World Wear Footwear\\nLatest Exclusive Affordab...          ₹259  \n",
       "16  edisson\\n001-Original Luxury Branded Fashionab...          ₹559  \n",
       "17  kardam&sons\\nCanvas Casual Partywear Outdoor S...          ₹449  \n",
       "18  SFR\\nPLANCK Smart Grey Lace-Ups Casuals Sneake...          ₹209  \n",
       "19  Deals4you\\nSneakers For Women\\n₹449₹99955% off...          ₹449  \n",
       "20  Roadster\\nMen Blue Solid Sneakers Sneakers For...          ₹999  \n",
       "21  BOLLERO\\nTrendy Sporty Shoes For Mens Sneakers...          ₹699  \n",
       "22  BRUTON\\nLattest Sneakers Shoe Sneakers For Men...          ₹279  \n",
       "23  ASTEROID\\nColorblock men's fancy sneakers Kore...          ₹494  \n",
       "24  SFR\\nPLANCK Smart Red Lace-Ups Casuals Sneaker...          ₹209  \n",
       "25  aadi\\nSynthetic| Lightweight| Premiun| Comfort...          ₹399  \n",
       "26  Numenzo\\nSneakers For Men\\n₹449₹1,04557% off\\n...          ₹449  \n",
       "27  JAMARION\\nModern Trendy Sneakers Shoes Sneaker...          ₹499  \n",
       "28  Bond Street By Red Tape\\nSneakers For Men\\n₹1,...        ₹1,274  \n",
       "29  SFR\\nSneakers For Men\\n₹269₹99973% off\\nFree d...          ₹269  \n",
       "30  edisson\\nCasual Sneakers Canvas Shoes For Men ...          ₹549  \n",
       "31  kardam&sons\\nCanvas Casual Partywear Outdoor S...          ₹413  \n",
       "32  World Wear Footwear\\nExclusive Affordable Coll...          ₹259  \n",
       "33  Labbin\\nSneakers For Men\\n₹399₹99960% off\\nFre...          ₹399  \n",
       "34  SFR\\nPLANCK Smart Blue Lace-Ups Casuals Sneake...          ₹209  \n",
       "35  Robbie jones\\nSneakers For Men\\n₹439₹1,02257% ...          ₹439  \n",
       "36  kardam&sons\\nCanvas Casual Partywear Outdoor S...          ₹449  \n",
       "37  kardam&sons\\nCanvas Casual Partywear Outdoor S...          ₹449  \n",
       "38  Kraasa\\nCasuals, Canvas, Partywear Sneakers Fo...          ₹499  \n",
       "39  RED TAPE\\nSneakers For Men\\n₹1,749₹4,99965% of...        ₹1,749  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making DataFrame...\n",
    "df = pd.DataFrame({'Brand_name': brand_title,'Product_discription': product_discription, 'Product_price': product_price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd4af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c5b243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cb8a92d",
   "metadata": {},
   "source": [
    "7. Web- Scraping Laptop from amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d295378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the amazon page automated on chrome browser...\n",
    "\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185497eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "rating = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdb70ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scarp the title from the given page..\n",
    "\n",
    "laptop_tags = driver.find_elements(By.XPATH,'//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "for i in laptop_tags[0:10]:\n",
    "    laptop = i.text\n",
    "    title.append(laptop)\n",
    "    \n",
    "# scrap the rating from the given page...\n",
    "\n",
    "star_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-size-base\"]')\n",
    "for i in star_tags[0:10]:\n",
    "    star = i.text\n",
    "    rating.append(star)\n",
    "    \n",
    "# scrap the price from the given page...\n",
    "\n",
    "rate_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in rate_tags[0:10]:\n",
    "    rate = i.text\n",
    "    price.append(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a6b9653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>81,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>95,046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title_name Rating   Price\n",
       "0  Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...    4.3  82,990\n",
       "1  HP Victus Gaming Latest 12th Gen Intel Core i7...    4.3  81,990\n",
       "2  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...    4.0  95,046\n",
       "3                                                                  \n",
       "4                                                                  \n",
       "5                                                                  \n",
       "6                                                                  \n",
       "7                                                                  \n",
       "8                                                                  \n",
       "9                                                                  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making DataFrame..\n",
    "\n",
    "df = pd.DataFrame({'Title_name': title, 'Rating': rating, 'Price': price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34cef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f066f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e31167d9",
   "metadata": {},
   "source": [
    "8. Web- Scraping the Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00c339a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the quotes page automated on chrome browser...\n",
    "\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3102fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = []\n",
    "quotes = []\n",
    "types_of_quotes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "936c50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap author from the given page..\n",
    "\n",
    "name_tags = driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in name_tags:\n",
    "    name = i.text\n",
    "    author.append(name)\n",
    "    \n",
    "# scrap quotes from the given page...\n",
    "\n",
    "topic_tags = driver.find_elements(By.XPATH,'//div[@class=\"wrap-block\"]')\n",
    "for i in topic_tags:\n",
    "    topic = i.text\n",
    "    quotes.append(topic)\n",
    "    \n",
    "    \n",
    "# scrap types of quotes from the given page...\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in title_tags:\n",
    "    title = i.text\n",
    "    types_of_quotes.append(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ca1126f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5740\\1165839844.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Making DataFrame....\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Author'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mauthor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Topic'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mquotes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Title'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtypes_of_quotes\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Making DataFrame....\n",
    "\n",
    "df = pd.DataFrame({'Author': author, 'Quotes': quotes, 'Title': types_of_quotes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb3c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc367577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b078649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
