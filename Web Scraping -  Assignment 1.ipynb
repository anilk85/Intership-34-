{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84c1855",
   "metadata": {},
   "source": [
    "# WEB SCRAPING - Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6625961e",
   "metadata": {},
   "source": [
    "1. Web Scraping using BeautifulSoup from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a1ecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in c:\\users\\kumar\\appdata\\roaming\\python\\python39\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n"
     ]
    }
   ],
   "source": [
    "# install BeautifulSoup and requests...\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03fe45",
   "metadata": {},
   "source": [
    "Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e89723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries...\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa35392c",
   "metadata": {},
   "source": [
    "Send get request to the webpage server to get the source code of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f4f35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server.... to get source code of the page..\n",
    "\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f185ef",
   "metadata": {},
   "source": [
    "Page Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a14158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pgae Content\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c71e22",
   "metadata": {},
   "source": [
    "Scraping the Header Tag from Wikipidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2198ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first,we will use the html tag for the result...\n",
    "\n",
    "wiki = soup.find('span',class_=\"mw-headline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c4e01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Wikipedia',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple header tag...\n",
    "\n",
    "wiki = []  # empty list\n",
    "for i in soup.find_all('span',class_=\"mw-headline\"):\n",
    "    wiki.append(i.text)\n",
    "    \n",
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75de700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5cfda0b",
   "metadata": {},
   "source": [
    "2. Web Scraping using BeutifulSoup IMDB top 100 Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bad57a",
   "metadata": {},
   "source": [
    "Send get request to the webpage server to get the source code of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfca96a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.imdb.com/search/title/?count=100&groups=top_1000&sort=user_rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1ac19",
   "metadata": {},
   "source": [
    "Page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c85352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7c020",
   "metadata": {},
   "source": [
    "Scraping the Name,Rating,Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c49981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "\n",
    "for i in soup2.find_all('h3',class_ = \"lister-item-header\"):\n",
    "    name.append(i.text.replace('\\n','').split('.')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdb3e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the movie rating....\n",
    "\n",
    "rating = []\n",
    "for i in soup2.find_all('div',class_ = \"inline-block ratings-imdb-rating\"):\n",
    "    rating.append(i.text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e12a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the Movie year....\n",
    "\n",
    "year = []\n",
    "for i in soup2.find_all('span',class_ = \"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d2ff38",
   "metadata": {},
   "source": [
    "Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39367b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of movie</th>\n",
       "      <th>Movie rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption(1994)</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather(1972)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight(2008)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lord of the Rings: The Return of the King(...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schindler's List(1993)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Witness for the Prosecution(1957)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Paths of Glory(1957)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Sunset Blvd</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1950)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Great Dictator(1940)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1940)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Chhichhore(2019)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Name of movie Movie rating  \\\n",
       "0                      The Shawshank Redemption(1994)          9.3   \n",
       "1                                 The Godfather(1972)          9.2   \n",
       "2                               The Dark Knight(2008)          9.0   \n",
       "3   The Lord of the Rings: The Return of the King(...          9.0   \n",
       "4                              Schindler's List(1993)          9.0   \n",
       "..                                                ...          ...   \n",
       "95                  Witness for the Prosecution(1957)          8.4   \n",
       "96                               Paths of Glory(1957)          8.4   \n",
       "97                                        Sunset Blvd          8.4   \n",
       "98                           The Great Dictator(1940)          8.4   \n",
       "99                                   Chhichhore(2019)          8.3   \n",
       "\n",
       "   Year of release  \n",
       "0           (1994)  \n",
       "1           (1972)  \n",
       "2           (2008)  \n",
       "3           (2003)  \n",
       "4           (1993)  \n",
       "..             ...  \n",
       "95          (1957)  \n",
       "96          (1957)  \n",
       "97          (1950)  \n",
       "98          (1940)  \n",
       "99          (2019)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dataframe.....\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Name of movie': name,'Movie rating': rating,'Year of release': year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11bcb66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f166f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57b466e7",
   "metadata": {},
   "source": [
    "3. Web Scraping using BeutifulSoup IMDB top 100 Indian Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6598839",
   "metadata": {},
   "source": [
    "Send get request to the webpage server to get source code of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae1a029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.imdb.com/list/ls009997493/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190409d4",
   "metadata": {},
   "source": [
    "Page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c5bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup3 = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1719a58",
   "metadata": {},
   "source": [
    "Scraping the Name, Rating, Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc89af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "for i in soup3.find_all('h3', class_ =\"lister-item-header\"):\n",
    "    name.append(i.text.replace('\\n','').split('.')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b7580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the movie rating....\n",
    "\n",
    "rating = []\n",
    "for i in soup3.find_all('div',class_ =\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05c2a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the Movie year.....\n",
    "\n",
    "year = []\n",
    "for i in soup3.find_all('span', class_ =\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddc95b",
   "metadata": {},
   "source": [
    "Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37046016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Movie</th>\n",
       "      <th>Movie Rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rang De Basanti(2006)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Idiots(2009)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taare Zameen Par(2007)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dil Chahta Hai(2001)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swades: We, the People(2004)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wake Up Sid(2009)</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rangeela(1995)</td>\n",
       "      <td>7.4</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shatranj Ke Khilari(1977)</td>\n",
       "      <td>7.5</td>\n",
       "      <td>(1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Pyaar Ka Punchnama(2011)</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ek Hasina Thi(2004)</td>\n",
       "      <td>7.5</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name of Movie Movie Rating Year of release\n",
       "0          Rang De Basanti(2006)          8.1          (2006)\n",
       "1                 3 Idiots(2009)          8.4          (2009)\n",
       "2         Taare Zameen Par(2007)          8.4          (2007)\n",
       "3           Dil Chahta Hai(2001)          8.1          (2001)\n",
       "4   Swades: We, the People(2004)          8.2          (2004)\n",
       "..                           ...          ...             ...\n",
       "95             Wake Up Sid(2009)          7.6          (2009)\n",
       "96                Rangeela(1995)          7.4          (1995)\n",
       "97     Shatranj Ke Khilari(1977)          7.5          (1977)\n",
       "98      Pyaar Ka Punchnama(2011)          7.6          (2011)\n",
       "99           Ek Hasina Thi(2004)          7.5          (2004)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Name of Movie': name,'Movie Rating': rating,'Year of release': year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b28567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13c967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d44db2b",
   "metadata": {},
   "source": [
    "4. Web Scraping using BeautifulSoup list of respected former President of India"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d462589",
   "metadata": {},
   "source": [
    "Send get request to the Webpage server to get the source code of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46bb9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://presidentofindia.nic.in/former-presidents.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8676b983",
   "metadata": {},
   "source": [
    "Page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8c3960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup4 = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de7063c",
   "metadata": {},
   "source": [
    "Scraping the Name and Terms of office former president of India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e94ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the Name of former president of India....\n",
    "\n",
    "name = []\n",
    "for i in soup4.find_all('div',class_ =\"presidentListing\"):\n",
    "    name.append(i.find('h3').text.split('(')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d24ad815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the Term of office...\n",
    "\n",
    "office = []\n",
    "for i in soup4.find_all('div',class_ =\"presidentListing\"):\n",
    "    office.append(i.find('p').text.split('(')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa5e42",
   "metadata": {},
   "source": [
    "Mkaing Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b8c5fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President Name</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>Term of Office: 25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>Term of Office: 25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>Term of Office: 25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>Term of Office: 25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>Term of Office: 25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>Term of Office: 25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>Term of Office: 25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>Term of Office: 25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>Term of Office: 25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>Term of Office: 24 August, 1974 to 11 February...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>Term of Office: 3 May, 1969 to 20 July, 1969 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>Term of Office: 13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>Term of Office: 13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>Term of Office: 26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   President Name  \\\n",
       "0           Shri Ram Nath Kovind    \n",
       "1          Shri Pranab Mukherjee    \n",
       "2   Smt Pratibha Devisingh Patil    \n",
       "3         DR. A.P.J. Abdul Kalam    \n",
       "4           Shri K. R. Narayanan    \n",
       "5        Dr Shankar Dayal Sharma    \n",
       "6            Shri R Venkataraman    \n",
       "7               Giani Zail Singh    \n",
       "8      Shri Neelam Sanjiva Reddy    \n",
       "9       Dr. Fakhruddin Ali Ahmed    \n",
       "10  Shri Varahagiri Venkata Giri    \n",
       "11              Dr. Zakir Husain    \n",
       "12  Dr. Sarvepalli Radhakrishnan    \n",
       "13           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       Term of Office  \n",
       "0     Term of Office: 25 July, 2017 to 25 July, 2022   \n",
       "1     Term of Office: 25 July, 2012 to 25 July, 2017   \n",
       "2     Term of Office: 25 July, 2007 to 25 July, 2012   \n",
       "3     Term of Office: 25 July, 2002 to 25 July, 2007   \n",
       "4     Term of Office: 25 July, 1997 to 25 July, 2002   \n",
       "5     Term of Office: 25 July, 1992 to 25 July, 1997   \n",
       "6     Term of Office: 25 July, 1987 to 25 July, 1992   \n",
       "7     Term of Office: 25 July, 1982 to 25 July, 1987   \n",
       "8     Term of Office: 25 July, 1977 to 25 July, 1982   \n",
       "9   Term of Office: 24 August, 1974 to 11 February...  \n",
       "10  Term of Office: 3 May, 1969 to 20 July, 1969 a...  \n",
       "11        Term of Office: 13 May, 1967 to 3 May, 1969  \n",
       "12       Term of Office: 13 May, 1962 to 13 May, 1967  \n",
       "13   Term of Office: 26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'President Name': name, 'Term of Office': office})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38391a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8fb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8089d279",
   "metadata": {},
   "source": [
    "5. Web Scrapping using BeutifulSoup Cricket Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf7280",
   "metadata": {},
   "source": [
    "Send get request to the Webpage Server to get the source code of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "979558cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454df53",
   "metadata": {},
   "source": [
    "Page Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb6d63db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page content...\n",
    "\n",
    "soup5 = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da765ee9",
   "metadata": {},
   "source": [
    "Scraping the top 10 cricket teams along with matches,points,rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4acb6bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrap Team Name..\n",
    "\n",
    "team = []\n",
    "for i in soup5.find_all('span', class_ =\"u-hide-phablet\"):\n",
    "    team.append(i.text)\n",
    "    \n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5395a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14921e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap team matches...\n",
    "\n",
    "matches = []\n",
    "\n",
    "for i in soup5.find_all('td', class_ =\"rankings-block__banner--matches\"):\n",
    "    matches.append(i.text.replace('\\n', \"\"))\n",
    "    \n",
    "for i in soup5.find_all('td',class_ =\"table-body__cell u-center-text\"):\n",
    "    matches.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "255f244a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ebb8e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48872ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap team points....\n",
    "\n",
    "points = []\n",
    "\n",
    "for i in soup5.find_all('td',class_ = \"rankings-block__banner--points\"):\n",
    "    points.append(i.text.replace('\\n',\"\"))\n",
    "    \n",
    "for i in soup5.find_all('td', class_ = \"table-body__cell u-center-text\"):\n",
    "    points.append(i.text)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "390d483a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "790e274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap team rating..\n",
    "\n",
    "ratings= []\n",
    "\n",
    "for i in soup5.find_all('td',class_ = \"rankings-block__banner--rating u-text-right\"):\n",
    "    ratings.append(i.text.replace('\\n',\"\"))\n",
    "    \n",
    "for i in soup5.find_all('td',class_ =\"table-body__cell u-text-right rating\"):\n",
    "    ratings.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b737db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f824be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c99c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c00c0e8",
   "metadata": {},
   "source": [
    "7. Web- Scraping for News details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da06f665",
   "metadata": {},
   "source": [
    "Send get request to the webpage server to get the source of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40745e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.cnbc.com/world/?region=world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda861b3",
   "metadata": {},
   "source": [
    "Page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "980ba354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page content..\n",
    "\n",
    "soup7 = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52d21540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the News headlines...\n",
    "\n",
    "news = []\n",
    "\n",
    "for i in soup7.find_all('div', class_ = \"RiverHeadline-headline RiverHeadline-hasThumbnail\"):\n",
    "    news.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef346376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Celsius clients with collateral stuck on failed crypto platform turn to bankruptcy court for relief',\n",
       " \"Asset manager names 9 'cheap' stocks to buy as recession fears grow\",\n",
       " 'Startup backed by a Tesla investor says it can deliver a $300,000 flying car by 2025',\n",
       " \"Amazon's cloud unit faces cost-sensitive customers as economic fears mount\",\n",
       " \"Op-ed: Authoritarian rulers suffered new setbacks in 2022. Here's what the democratic world needs to do to seize the momentum\",\n",
       " 'Beijing, Shenzhen loosen more Covid curbs as China easing gathers pace',\n",
       " 'Big Tech is set for a comeback, asset manager says, naming 2 stocks to get ahead of it',\n",
       " 'These 10 cars have the greatest potential lifespan — and 6 are Toyotas',\n",
       " 'Chinese F1 Grand Prix canceled for 2023',\n",
       " 'The 10 countries with the least paid vacation—the U.S. is No. 2',\n",
       " \"35% of millionaires say it's 'going to take a miracle' to be ready for retirement, report finds\",\n",
       " 'Indonesia evacuates villagers as volcano erupts on Java island',\n",
       " 'Netherlands eliminates U.S. in round 16 of the World Cup',\n",
       " \"The Fed's path to a 'Goldilocks' economy just got a little more complicated\",\n",
       " 'Pentagon debuts its new stealth bomber, the B-21 Raider',\n",
       " \"The U.S. wants the EU to be strict with China. But Europe can't afford it\",\n",
       " 'U.S. expects reduced tempo in Ukraine fighting to continue for months',\n",
       " \"CNBC Pro Talks: Evercore's Mark Mahaney finds bargains in big tech and answers your questions\",\n",
       " 'Tech layoffs send visa holders on frantic search for employment to avoid deportation',\n",
       " 'Parking lots are becoming as important as cars in climate change efforts']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24367f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d72726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2367f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e24e5ee",
   "metadata": {},
   "source": [
    "8. Web-Scraping download articles from AI in 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263c41d",
   "metadata": {},
   "source": [
    "Send get request to the Webpage server get to the source code of webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "011e1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c5c9a",
   "metadata": {},
   "source": [
    "Pgae content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5782811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup8 = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ebb416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the paper title..\n",
    "\n",
    "title = []\n",
    "for i in soup8.find_all('h2', class_ = \"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19eaf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the Authors...\n",
    "\n",
    "name = []\n",
    "\n",
    "for i in soup8.find_all('span' , class_ = \"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85bfe702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the published Date...\n",
    "\n",
    "date = []\n",
    "\n",
    "for i in soup8.find_all('span', class_ = \"sc-1thf9ly-2 dvggWt\"):\n",
    "    date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4c440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea22918c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021  \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021  \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015  \n",
       "3                                 Boden, Margaret A.      August 1998  \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017  \n",
       "5                                        Miller, Tim    February 2019  \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021  \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015  \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999  \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020  \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021  \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007  \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016  \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021  \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997  \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021  \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021  \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021  \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016  \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021  \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021  \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014  \n",
       "22                      Kohavi, Ron, John, George H.    December 1997  \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021  \n",
       "24                                   Ying, Mingsheng    February 2010  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Making DataFrame...\n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Paper title': title, 'Authors': name, 'Published Date': date})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6065a357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b91f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98a1253b",
   "metadata": {},
   "source": [
    "9. web Scraping form dineout.co.in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ce777",
   "metadata": {},
   "source": [
    "Send get request to the webpage server to get the source of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6f0aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ddf0b",
   "metadata": {},
   "source": [
    "Page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f80bc0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup9 = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7510ceda",
   "metadata": {},
   "source": [
    "Scraping Restaurants Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff9cd096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Restaurants\n",
    "\n",
    "name = []\n",
    "\n",
    "for i in soup9.find_all('a', class_= \"restnt-name ellipsis\"):\n",
    "    name.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c52317f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the location..\n",
    "\n",
    "loc = []\n",
    "\n",
    "for i in soup9.find_all('div',class_ = \"restnt-loc ellipsis\"):\n",
    "    loc.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7888e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the ratings...\n",
    "\n",
    "images = []\n",
    "\n",
    "for i in soup9.find_all('img', class_ = \"no-img\"):\n",
    "    images.append(i.get('data-src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "262de5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the rating...\n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in soup9.find_all('div', class_ = \"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5950f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Loction</th>\n",
       "      <th>Images</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant Name  \\\n",
       "0                   Castle Barbeque   \n",
       "1                   Jungle Jamboree   \n",
       "2                   Castle Barbeque   \n",
       "3                        Cafe Knosh   \n",
       "4              The Barbeque Company   \n",
       "5                       India Grill   \n",
       "6                    Delhi Barbeque   \n",
       "7  The Monarch - Bar Be Que Village   \n",
       "8                 Indian Grill Room   \n",
       "\n",
       "                                             Loction  \\\n",
       "0                     Connaught Place, Central Delhi   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "2             Pacific Mall,Tagore Garden, West Delhi   \n",
       "3  The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "4                 Gardens Galleria,Sector 38A, Noida   \n",
       "5               Hilton Garden Inn,Saket, South Delhi   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "\n",
       "                                              Images Rating  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...    4.1  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...    3.9  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...    3.9  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...    4.3  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...      4  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...    3.9  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...    3.6  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...    3.8  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...    4.3  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making DataFrame....\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Restaurant Name': name, 'Loction':loc, 'Images': images, 'Rating': rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f13c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18fcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59b89f5e",
   "metadata": {},
   "source": [
    "10. Web- Scraping the details for top publication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70465517",
   "metadata": {},
   "source": [
    "Send get requests to the webpage server get the source code of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1194bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67df081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page content...\n",
    "\n",
    "soup10 = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9e2fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the Publication..\n",
    "\n",
    "publication = []\n",
    "\n",
    "for i in soup10.find_all('td', class_ = \"gsc_mvt_t\"):\n",
    "    publication.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1dc166dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping h5- index....\n",
    "\n",
    "index = []\n",
    "\n",
    "for i in soup10.find_all('td', class_ =\"gsc_mvt_n\"):\n",
    "    index.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d69ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping h5- median....\n",
    "\n",
    "median = []\n",
    "\n",
    "for i in soup10.find_all('span', class_ =\"gs_ibl gsc_mp_anchor\"):\n",
    "    median.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb123ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
